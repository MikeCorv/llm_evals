# llm_evals
This repository contains a collection of Colab notebooks used to evaluate various Large Language Models (LLMs) on the MMLU (Massive Multitask Language Understanding) benchmark.
